{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate, MessagesPlaceholder, PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pathlib import Path\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.output_parsers import PydanticToolsParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
    "from typing import Sequence, List\n",
    "from langgraph.graph import MessageGraph, END\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to call a path to the file and read it. \n",
    "def context_gen(file_name):\n",
    "    Folder = \"VertexLang\"\n",
    "    here = Path(locals().get('__file__', Folder)).resolve()\n",
    "    parameter = (here / file_name).read_text()\n",
    "    return parameter\n",
    "\n",
    "#remove code fences from the output\n",
    "def remove_code_fences(text):\n",
    "    lines = text.split(\"\\n\")\n",
    "    lines = [line for line in lines if not line.strip().startswith('```')]\n",
    "    lines[0] = lines[0].replace(' -', '-', 1)\n",
    "    print()\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "#invoke and run the model with the given prompt\n",
    "def test_vertexai(few_shot_prompt):\n",
    "    generate = ChatPromptTemplate.from_messages([(\"system\", system), few_shot_prompt, (\"human\", human), (\"ai\", someoutput)])\n",
    "    chat = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.5)\n",
    "    #select an output parser\n",
    "    output_parser = StrOutputParser()\n",
    "    chain = generate | chat | output_parser\n",
    "    result = chain.invoke({})\n",
    "    print(remove_code_fences(result))\n",
    "    print()\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create inputs to the model, telling it what needs to be done. \n",
    "#provides system message\n",
    "system = context_gen(\"systemmsg.txt\")\n",
    "\n",
    "#provides the few shot examples\n",
    "output_examples = context_gen(\"outputex.txt\")\n",
    "\n",
    "#provides the input examples\n",
    "input_examples = context_gen(\"inputex.txt\")\n",
    "\n",
    "#provides the database schema\n",
    "schema = context_gen(\"dataBaseSchema.txt\")\n",
    "\n",
    "refsystem = context_gen(\"ref_system copy.txt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few shot prompts example template "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"input\": input_examples, \"output\": output_examples},\n",
    "]\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"ai\", \"{output}\"),\n",
    "]\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubQuery(BaseModel):\n",
    "    '''Search for the geometric definition of a feature across the vector database'''\n",
    "\n",
    "    sub_query: str = Field(\n",
    "        ...,\n",
    "        description=\"The text to be used as a sub-query in the prompt.\",\n",
    "    )   \n",
    "\n",
    "#First input to the model, breaks query down and provides geometry definition\n",
    "\n",
    "class YamlText(BaseModel):\n",
    "    text: str = Field(SQLQuery = \"Yaml Text printed one line at a time\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the definition of the xy plane?\n"
     ]
    }
   ],
   "source": [
    "#This model sends the user query to the LLM, which then breaks it down into smaller parts if there are words it does not understand\"\"\"\n",
    "\n",
    "'''change the human variable to test different inputs'''\n",
    "human = (\"select all faces with radius less than 20 in the xy plane\")\n",
    "\n",
    "system2 = context_gen(\"system2.txt\")\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system2), (\"human\", human),])\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.5, )\n",
    "chat_with_tools = chat.bind_tools([SubQuery])\n",
    "parser = PydanticToolsParser(tools=[SubQuery])\n",
    "query_analyzer = prompt | chat_with_tools | parser \n",
    "output = query_analyzer.invoke({}, {\"tags\": [\"loop 001\"]})\n",
    "result = output[0].sub_query\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The xy plane, in terms of CAD geometrical features, can be defined as a planar surface that is perpendicular to the z-axis and contains both the x-axis and y-axis. It is a fundamental geometric construct that serves as a reference plane for creating and manipulating 2D and 3D objects in computer-aided design (CAD) software.\n"
     ]
    }
   ],
   "source": [
    "#The next step is to generate a definition of the words it did not understand, based on the broken down query in the previous step\"\"\"\n",
    "\n",
    "#get context file \n",
    "system3 = context_gen(\"reflect1.txt\")\n",
    "\n",
    "#chat prompt template for defining the words \n",
    "definer = ChatPromptTemplate.from_messages([(\"system\", system3), (\"human\", result)])\n",
    "chat = ChatVertexAI(model_name=\"gemini-1.0-pro\", temperature=0.5, convert_system_message_to_human=True)\n",
    "\n",
    "#using string output parser as the output is a string\n",
    "output_parser = StrOutputParser()\n",
    "chain2 = definer | chat \n",
    "definition = chain2.invoke({}, {\"tags\":[\"loop 002\"]})\n",
    "print(definition.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prompt = ChatPromptTemplate.from_messages([(\"system\", system), MessagesPlaceholder(variable_name=\"messages\")])\n",
    "base_chain = base_prompt | chat \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The next step is to ask the model to carry out a self reflection on the output that it generated in the previous step and provide feedback on the same, after which it generates an improved output taking the same feedback into consideration.\"\"\"\n",
    "\n",
    "reflection_prompt = ChatPromptTemplate.from_messages([(\"system\", refsystem), few_shot_prompt, (\"ai\", definition.content), MessagesPlaceholder(variable_name=\"messages\"), ])\n",
    "\n",
    "#the chat variable below can be changed if reflection needs to be used from a different LLM model. \n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.5)\n",
    "\n",
    "#chain for the reflection prompt.\n",
    "reflect = reflection_prompt | chat \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'__end__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m graph \u001b[38;5;241m=\u001b[39m builder\u001b[38;5;241m.\u001b[39mcompile()\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mastream([HumanMessage(content\u001b[38;5;241m=\u001b[39mhuman)]):\n\u001b[1;32m---> 29\u001b[0m     ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_messages(event[END])\u001b[38;5;241m.\u001b[39mpretty_print()\n",
      "\u001b[1;31mKeyError\u001b[0m: '__end__'"
     ]
    }
   ],
   "source": [
    "async def generation_node(state: Sequence[BaseMessage]):\n",
    "    return await base_chain.ainvoke({\"messages\": state}, {\"tags\": [\"loop 003\"]})\n",
    "\n",
    "\n",
    "async def reflection_node(messages: Sequence[BaseMessage]) -> List[BaseMessage]:\n",
    "    # Other messages we need to adjust\n",
    "    cls_map = {\"ai\": HumanMessage, \"human\": AIMessage}\n",
    "    # First message is the original user request. We hold it the same for all nodes\n",
    "    translated = [messages[0]] + [cls_map[msg.type](content=msg.content) for msg in messages[1:]]\n",
    "    res = await reflect.ainvoke({\"messages\": translated})\n",
    "    # We treat the output of this as human feedback for the generator\n",
    "    return HumanMessage(content=res.content)\n",
    "\n",
    "builder = MessageGraph()\n",
    "builder.add_node(\"gemini-pro\", generation_node)\n",
    "builder.add_node(\"OpenAi\", reflection_node)\n",
    "builder.set_entry_point(\"gemini-pro\")\n",
    "\n",
    "def should_continue(state: List[BaseMessage]):\n",
    "    if len(state) > 5:\n",
    "        return END\n",
    "    return \"OpenAi\"\n",
    "\n",
    "builder.add_conditional_edges(\"gemini-pro\", should_continue)\n",
    "builder.add_edge(\"OpenAi\", \"gemini-pro\")\n",
    "graph = builder.compile()\n",
    "\n",
    "async for event in graph.astream([HumanMessage(content=human)]):\n",
    "    ChatPromptTemplate.from_messages(event[END]).pretty_print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "select all faces with radius less than 20 in the xy plane\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "- filter: select * from faces where radius < 20 and type like \"Planar\" and normal_zangle = 0\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "The provided YAML text is accurate and well-structured. It effectively filters faces with a radius less than 20 in the xy plane by checking for faces with a radius less than 20, a type of \"Planar\", and a normal z-angle of 0. This ensures that only faces in the xy plane are selected. Great job!\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "- filter: select * from faces where radius < 20 and type like \"Planar\" and normal_zangle = 0\n",
      "- expand: bodyfaces\n",
      "- filter: select * from bodies where volume > 1000000\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "The YAML text provided is correct and follows the specified format. It first filters faces with a radius less than 20 in the xy plane by checking for faces with a radius less than 20, a type of \"Planar\", and a normal z-angle of 0. Then it expands to select the faces attached to the body and filters bodies with a volume greater than 1000000. The logic is sound and the commands are appropriately structured. Well done!\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "- filter: select * from edges where type like \"Linear\" and length > 100\n",
      "- expand: edgefaces\n",
      "- filter: select * from faces where type like \"Cylindrical\" and radius > 10\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
