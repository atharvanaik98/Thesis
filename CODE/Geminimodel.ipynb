{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "import requests\n",
    "from vertexai.preview.generative_models import GenerativeModel, ChatSession\n",
    "\n",
    "#initiate the vertex AI with project ID \n",
    "vertexai.init(project = \"totemic-veld-412608\")\n",
    "\n",
    "#function definition to remove code fences from the printed output \n",
    "def remove_code_fences(text):\n",
    "    lines = text.split('\\n')\n",
    "    lines = [line for line in lines if not line.strip().startswith('```')]\n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "#Github location url for the context file stored in the repository \n",
    "repo_url = \"https://raw.githubusercontent.com/firestorm98/Thesis/main/Input.txt\"\n",
    "TOKEN = \"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\"\n",
    "headers = {\n",
    "    \"authorization\": f\"token {TOKEN}\", \n",
    "    \"Accept\": \"text/plain\"\n",
    "}\n",
    "\n",
    "#Append the contents of the input file to a variable named context \n",
    "context = requests.get(repo_url, headers=headers)\n",
    "\n",
    "#select the generative model \n",
    "model = GenerativeModel(\"gemini-pro\")\n",
    "\n",
    "#initiate interactive chat environment \n",
    "chat = model.start_chat()\n",
    "\n",
    "#Extract the content in the form of text \n",
    "context = context.text\n",
    "\n",
    "#send context as input to the model and prepare for user prompt\n",
    "chat.send_message(context)\n",
    "\n",
    "#Input the prompt here\n",
    "prompt = input(\"Enter the description of the geometry you want to select: \")\n",
    "if prompt == \"cancel\":\n",
    "    prompt = \"cancel\"\n",
    "else: \n",
    "#Generate a response based on the prompt\n",
    "    response = chat.send_message(prompt)\n",
    "\n",
    "    print()\n",
    "    #print model response\n",
    "    print(remove_code_fences(response.text))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyGKN (myenv, 3.11.6)",
   "language": "python",
   "name": "pygkn-myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
